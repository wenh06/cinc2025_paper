\section{Discussion and Conclusions}
\label{sec:discu}

% almost finished.

The hidden validation Challenge score presented in Table~\ref{tab:scores} indicates that our proposed method is effective for Chagas screening from ECGs, albeit with substantial room for improvement. The result demonstrates our model's ability to learn diagnostically relevant features from ECGs for this task under scarce and noisy supervision. This is achieved through reliability-aware label smoothing, which incorporates both label provenance and reliability instead of treating all positive labels uniformly. Together with the asymmetric loss and strategic upsampling, these results indicate that explicitly modeling label reliability helps stabilize the learning process more effectively than introducing additional architectural complexity. Overall, our approach aligns well with the Challenge's objective of identifying high-risk individuals under limited serological testing capacity.

However, the performance gap between our internal hold-out subset and the hidden validation set suggests two primary limitations. First, the reliability weights (smoothing factors) were pre-defined based on label provenance rather than learned from data. This static assignment cannot capture the inherent heterogeneity of label quality within each source. Second, positive upsampling was applied uniformly at the dataset level using fixed factors. This strategy overlooks variations in individual sample difficulty and does not adapt to the model's evolving confidence during training. Furthermore, we did not make use of the additional labels available in some datasets, such as arrhythmia labels, to design and implement auxiliary learning tasks that could have enhanced the performance of the main task, Chagas screening.

Future research directions will primarily focus on the development of a self-adaptive supervision framework. This includes dynamic weighting schemes for learning instance-specific reliability scores, moving beyond static smoothing factors; and adaptive sampling strategies that respond to the model's evolving confidence during training, offering a promising alternative to fixed upsampling factors. Data augmentation techniques, such as CutMix \cite{yun2019cutmix} and SMOTE \cite{Chawla_2002_SMOTE}, could be applied to further expand and diversify the positive samples, thereby enhancing the model's robustness. Additionally, a multi-task learning framework leveraging auxiliary arrhythmia labels could enhance feature representation and improve generalization for the primary Chagas screening task.
