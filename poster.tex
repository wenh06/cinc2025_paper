%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NIWeek 2014 Poster by T. Reveyrand
% www.microwave.fr
% http://www.microwave.fr/LaTeX.html
% ---------------------------------------
%
% Original template created by:
% Brian Amberg (baposter@brian-amberg.de)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0paper,portrait]{baposter}

\input{preamble}

\usepackage{textcomp}
\usepackage{eso-pic}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{fix-cm}

\setlist[itemize]{
  itemsep=1.5pt,
  topsep=3pt,
  parsep=0pt,
  partopsep=0pt,
  leftmargin=1em,
  labelsep=0.4em
}

\setlength{\abovedisplayskip}{1.5pt plus 1pt minus 1pt}
\setlength{\belowdisplayskip}{1.5pt plus 1pt minus 1pt}

\graphicspath{{images/}} % Directory in which figures are stored

\definecolor{bordercol}{RGB}{40,40,40} % Border color of content boxes
\definecolor{headercol1}{RGB}{186,215,230} % Background color for the header in the content boxes (left side)
\definecolor{headercol2}{RGB}{120,120,120} % Background color for the header in the content boxes (right side)
\definecolor{headerfontcol}{RGB}{0,0,0} % Text color for the header text in the content boxes
\definecolor{boxcolor}{RGB}{210,235,250} % Background color for the content in the content boxes

\definecolor{jdhblue}{RGB}{2,93,186}

\definecolor{zkblue}{RGB}{88,135,175}
\definecolor{zkbackground}{RGB}{230,232,234}


% \usetikzlibrary{shapes, arrows, external, decorations.pathmorphing, backgrounds, positioning, fit, petri, calc, hobby, cd}


\begin{document}

% \background{ % Set the background to an image (background.pdf)
% \begin{tikzpicture}[remember picture,overlay]
% \draw (current page.north west)+(-2em,2em) node[anchor=north west]
% {\includegraphics[height=1.1\textheight]{images/baposter_background.pdf}};
% \end{tikzpicture}
% }

% add conference banner
\AddToShipoutPictureFG*{%
  \AtPageLowerLeft{%
    \hspace{0.77em}
    \raisebox{0.2ex}{\includegraphics[width=0.147\textwidth]{cinc2025-banner.png}}
  }
}

\begin{poster}{
grid=false,
borderColor=bordercol, % Border color of content boxes
headerColorOne=headercol1, % Background color for the header in the content boxes (left side)
headerColorTwo=headercol2, % Background color for the header in the content boxes (right side)
headerFontColor=headerfontcol, % Text color for the header text in the content boxes
% boxColorOne=boxcolor, % Background color for the content in the content boxes
boxColorOne=zkbackground,
headershape=roundedright, % Specify the rounded corner in the content box headers
headerfont=\Large\sf\bf, % Font modifiers for the text in the content box headers
textborder=rectangle,
% background=user,
background=none,
headerborder=open, % Change to closed for a line under the content box headers
boxshade=plain
}
%
%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR NAME
%----------------------------------------------------------------------------------------
%
{\includegraphics[scale=0.385]{logo_cau_science.png}} % University/lab logo
{
{\bf \fontsize{17pt}{17pt} \selectfont Reliability-Aware Hierarchical Learning for Chagas Detection from ECG under Expert Label Scarcity}
} % Poster title
{\vspace{0.3em} \smaller Hao WEN$^1$, Jingsu KANG$^2$  \\  % Author names

$^1${\it College of Science, China Agricultural University}\qquad
$^2${\it Tianjin Medical University} \\
\vspace{0.2cm}
{\Large \bf{The George B. Moody PhysioNet Challenge 2025}, ~~~\bf{Team Revenger}}
}
{\includegraphics[scale=0.097]{logo_tmu.jpeg}}


\newif\ifcoloredtext
\coloredtexttrue
\newif\ifboxednn
\boxednntrue


%----------------------------------------------------------------------------------------
%	INTRODUCTION & CHALLENGE CONTEXT
%----------------------------------------------------------------------------------------

\headerbox{Framework Summary \& Key Components}{name=introduction, column=0, row=0, span=3}{

\begin{itemize}
\item We propose a \textbf{reliability-aware hierarchical framework} for ECG-based Chagas screening under scarce and noisy labels. The framework comprises three coordinated components: (1) provenance‑stratified label smoothing, (2) moderated source-specific upsampling, and (3) a lightweight variable‑length bottleneck ResNet classifier.
\item The supervision design assigns sharp targets to expert‑confirmed positives, softened targets to self‑reported samples, and mild smoothing to non‑endemic negatives, while distinct upsampling factors amplify scarce reliable positives without collapsing cohort diversity.
\item The encoder stacks 4 bottleneck residual blocks with a global squeeze‑and‑excitation module and global max pooling to handle variable-length inputs; training couples reliability‑coded targets with an asymmetric loss to concentrate learning on hard positives amid severe class imbalance.
\end{itemize}
}

%----------------------------------------------------------------------------------------
%	DATA
%----------------------------------------------------------------------------------------

\headerbox{Dataset Preparation}{name=data, column=0, row=1, span=1, below=introduction}{

\begin{itemize}
\item \textbf{Sampling}: All 12-lead ECGs uniformly resampled to 400 Hz.
\item \textbf{Filtering}: Butterworth bandpass 0.5–45 Hz to suppress baseline wander + high-frequency noise.
\item \textbf{Normalization}: Per-record z-score
\begingroup
\setlength{\abovedisplayskip}{2pt}  % 上间距
\setlength{\belowdisplayskip}{2pt}  % 下间距
\[
\tilde{\mathbf{x}} = \frac{\mathbf{x} - \boldsymbol{\mu}_{\mathbf{x}}}{\boldsymbol{\sigma}_{\mathbf{x}}}
\]
\endgroup
to zero mean, unit variance.
\item \textbf{Exclusion criteria}: Discard recordings $<1{,}200$ samples ($<3$ s @ 400 Hz) to ensure enough cardiac cycles.
\end{itemize}

}

%----------------------------------------------------------------------------------------
%	RELIABILITY-AWARE SUPERVISION
%----------------------------------------------------------------------------------------

\headerbox{Reliability-Aware Supervision}{name=supervision, column=1, row=1, span=2, below=introduction}{

% Three ECG datasets with heterogeneous label reliability and Chagas prevalence:

Hierarchical supervision: source reliability levels (expert > self-report > non-endemic negatives) $\longrightarrow$ calibrated label smoothing ($\varepsilon$) + moderated upsampling.

\vspace{-1ex}
% {\smaller[1]
\begin{center}
\begin{tabular}{rlllllll}
\toprule
\multirow{2}{*}{Dataset} & \multirow{2}{*}{Size} & \multirow{2}{*}{Chagas \%} & \multirow{2}{*}{Provenance} & \multirow{2}{*}{Up $\times$} & \multirow{2}{*}{$\varepsilon$} & \multicolumn{2}{c}{Smoothed Targets} \\ \cmidrule(lr){7-8}
& & & & & & negative & positive \\
\midrule
SaMi-Trop   & 1,631     & 100 \%    & expert-confirmed  & $\times$ 12 & 0.0 & N/A           & $[0,\,1]$     \\
CODE-15\%   & 345,779   & 1.795 \%  & self-reported     & $\times$ 3  & 0.6 & $[0.7,\,0.3]$ & $[0.3,\,0.7]$ \\
PTB-XL      & 21,799    & 0 \%      & non-endemic (neg) & $\times$ 1  & 0.2 & $[0.9,\,0.1]$ & N/A           \\
\bottomrule
\end{tabular}
\end{center}
% }
\vspace{-1ex}

Label smoothing (binary, $C=2$): $\tilde{\mathbf{y}} = (1 - \varepsilon) \cdot {\mathbf{y}} + \frac{\varepsilon}{C} \cdot {\mathbf{1}}$.

\begin{itemize}
% \item Reliability levels: expert (sharp, high upsampling) > self-report (soft, moderate) > non-endemic negatives (mild).
\item Purpose: reduce overconfident gradients for noisier self-reports while preserving expert signal.
% \item Upsampling balance: (CODE-15\% $\times$3, SaMi-Trop $\times$12) maximized hidden score; aggressive (10,120) overfit / degraded generalization.
% \item PTB-XL adds negative morphology diversity; mild smoothing (0.2) regularizes the decision boundary.
% \item Interaction: provenance-aware smoothing complements asymmetric loss (ASL) by encoding prior trust.
\item Benefit: replaces ad-hoc class weights with structured priors; stabilizes early training variance.
% \item Limitation: $\varepsilon$ values are manually fixed—do not capture intra-source heterogeneity (future: learn instance reliability).
\item Complementarity: provenance-based smoothing reduces label noise impact; ASL (asymmetric loss) focuses capacity on hard positives:
\begingroup
\setlength{\abovedisplayskip}{2pt}  % 上间距
\setlength{\belowdisplayskip}{2pt}  % 下间距
\[
\operatorname{ASL} = -y \cdot (1-p)^{\gamma_{+}} \log(p) - (1-y) \cdot (p_m)^{\gamma_{-}} \log(1-p_m)
\]
\endgroup
where $p$ is the predicted probability of the positive class, $y$ is the (smoothed) positive-class target probability, $p_m = \max(p - m, 0),$ $(\gamma_{+},\gamma_{-})=(1,4)$ and margin $m=0.05$.
\end{itemize}

}

%----------------------------------------------------------------------------------------
%	MODEL ARCHITECTURE
%----------------------------------------------------------------------------------------

\headerbox{Model Architecture}{name=model, column=0, row=2, span=1, below=data}{

{\bf Enhanced 1D ResNet with SE Modules}

\vspace{-3.5ex}

\begin{center}
\resizebox{1.03\linewidth}{!}{%
  \input{tikz_plots/resnet_nature_comm_bottle_neck}
}
\end{center}

\vspace{-2ex}

\begin{itemize}
\item {\bf Stem}: Conv1d (kernel 15, stride 1, 64 channels) followed by BN and ReLU, providing initial local morphology modeling.
\item {\bf Bottleneck blocks}: 1-15-1 convolutions, expansion factor 4, stride 4 downsampling
\item {\bf Global SE}: Channel attention, reduction ratio 8 for temporal feature recalibration.
\item {\bf Variable-length inputs}: Global MaxPool enables inference on ECGs of any duration.
% \item {\bf Classification MLP head}: Hidden FC layer ($1280 \to 1024$) with non-linear activation and dropout (rate 0.2), followed by a final linear layer ($1024 \to 2$) producing class logits.
\end{itemize}

}

%----------------------------------------------------------------------------------------
%	UPSAMPLING STRATEGY SELECTION
%----------------------------------------------------------------------------------------

\headerbox{Upsample Strategy Selection}{name=upsampling, column=1, row=2, span=1, below=supervision}{
\small
% \textbf{Goal:} Amplify scarce reliable positives without collapsing inter‑cohort diversity.

\begin{center}
\input{tables/upsampling_schemes}
\end{center}
\vspace{-1ex}
$^\dagger$ obtained during the unofficial phase.

\begin{itemize}
\item Moderate replication outperformed both no upsampling and extreme factors.
\item Extreme factors increased memorization and reduced hidden generalization.
% \item PTB-XL (negatives only) kept at ×1 to avoid further skew toward the negative class.
\end{itemize}

}

%----------------------------------------------------------------------------------------
%	TRAINING CONFIGURATION
%----------------------------------------------------------------------------------------

\headerbox{Training Configuration}{name=training, column=2, row=2, span=1, below=supervision}{

\begin{itemize}[leftmargin=8pt,itemsep=2pt,topsep=2pt]
\item \textbf{Optimizer \& scheduler}: AdamW (weight decay $1\times 10^{-2}$) with OneCycle LR over 30 epochs: base $1\times10^{-4} \rightarrow$ peak $6\times10^{-4}$ (early phase) $\rightarrow$ anneal to $\approx 1\times10^{-6}$.
% \item \textbf{Batch / epochs / early stop}: Batch size 128; max 30 epochs; early stopping (patience 10) on a fixed 20\% hold-out subset using the Challenge metric.
\item \textbf{Batch size}: 128.
\item \textbf{Epochs}: Max 30 epochs.
\item \textbf{Early stop}: Patience 10 epochs, evaluated on a fixed 20\% hold-out subset using the Challenge metric.
\item \textbf{Training segments}: Uniform random crop (or center padding if shorter) of 4{,}096 samples.
\item \textbf{Implementation}: PyTorch + \texttt{torch-ECG} framework

\end{itemize}
}

%----------------------------------------------------------------------------------------
%	RESULTS
%----------------------------------------------------------------------------------------

\headerbox{Results}{name=results, column=1, row=3, span=2, below=upsampling}{

% {\bf Challenge Performance \& Analysis}

\begin{center}
\begin{tabular}{r|r|r|r}
Internal hold-out (mean±std) & Hidden validation & Rank & Test \\
\hline
$0.451 \pm 0.005$ & 0.245 & 179/364 & TBA \\
\hline
\end{tabular}
\end{center}
\vspace{-1ex}
The rankings are based on the hidden validation set. Results on the public training data (more specifically, the hold-out subset) are also provided for reference.

}

%----------------------------------------------------------------------------------------
%	DISCUSSION & Limitations
%----------------------------------------------------------------------------------------

\headerbox{Discussion \& Limitations}{name=discussion, column=0, row=4, span=3, below=results}{

\begin{itemize}
\item Our reliability-aware hierarchical framework provides a lightweight, supervision-centric route to Chagas ECG screening under scarce positives and mixed label noise, without relying on heavy architectures or pretraining.
\item The generalization gap (internal hold-out vs hidden validation) suggests residual distribution shift (cohort composition/prevalence) and under-adaptation of our fixed supervision scheme.
\item Static supervision limits adaptation: (i) Fixed smoothing factors ($\varepsilon$) capture only coarse provenance, missing intra-source label quality variation; (ii) dataset-level upsampling with fixed multipliers ignores evolving model confidence and per-instance difficulty.
\item \textbf{Future directions}:
\begin{itemize}
\item Adaptive supervision: jointly learn instance-level reliability weights and adjust positive sampling (curriculum/difficulty- or confidence-aware, hard positive mining, etc.) instead of fixed smoothing factors $\varepsilon$ and static upsampling multipliers.
\item Augmentation \& synthesis: CutMix, mixup variants, temporal warping, and class-conditional synthesis to expand minority morphology diversity.
\item Multi-task \& pretraining: leverage arrhythmia / morphology labels; self-supervised ECG representation learning before supervised fine-tuning.
\end{itemize}
\end{itemize}

}

%----------------------------------------------------------------------------------------
%	FOOTER
%----------------------------------------------------------------------------------------

\headerbox{}{name=foottext, column=0, span=3, below=discussion, textborder=none, headerborder=none, boxheaderheight=0pt}{
\hfill \small \textit{Code, configs, etc. are available at https://github.com/wenh06/cinc2025, and is based on https://github.com/DeepPSP/torch\_ecg.}
}

\end{poster}

\end{document}
